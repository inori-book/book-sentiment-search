import streamlit as st
import pandas as pd
import requests
from janome.tokenizer import Tokenizer
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
import re
import unicodedata
from dotenv import load_dotenv
import os

load_dotenv()

# â”€â”€â”€ 1. ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæœ€åˆã«ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="æ„Ÿæƒ³å½¢å®¹è©ã§æ¢ã™æœ¬ã‚¢ãƒ—ãƒª", layout="wide")

# â”€â”€â”€ 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & å‰å‡¦ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_data(path: str = "sample07.csv") -> pd.DataFrame:
    df = pd.read_csv(path, dtype={"ISBN": str}).fillna("")
    df.columns = [col.lower() for col in df.columns]  # åˆ—åã‚’å°æ–‡å­—ã«çµ±ä¸€
    # ã‚¸ãƒ£ãƒ³ãƒ«ã‚’ãƒªã‚¹ãƒˆåŒ–
    df["genres_list"] = df["genre"].str.split(",").apply(lambda lst: [g.strip() for g in lst if g.strip()])
    # Janome ã§å½¢å®¹è©æŠ½å‡º
    tokenizer = Tokenizer()
    def extract_adjs(text: str) -> list[str]:
        return [t.base_form for t in tokenizer.tokenize(text) if t.part_of_speech.startswith("å½¢å®¹è©")]
    df["adjectives"] = df["review"].apply(extract_adjs)
    return df

df = load_data()

# â”€â”€â”€ 3. ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰å¤–éƒ¨åŒ– & å€™è£œå½¢å®¹è© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_stopwords(path: str = "stopwords.txt") -> set[str]:
    try:
        with open(path, encoding="utf-8") as f:
            words = {line.strip() for line in f if line.strip()}
    except FileNotFoundError:
        words = {"ãªã„", "ã£ã½ã„"}
    return words

def get_rakuten_app_id():
    return st.secrets.get("RAKUTEN_APP_ID") or os.getenv("RAKUTEN_APP_ID")

def normalize_isbn(isbn_str: str) -> str:
    """ISBNã‚’æ­£è¦åŒ–ã™ã‚‹ï¼ˆãƒã‚¤ãƒ•ãƒ³ã‚„ç©ºç™½ã‚’é™¤å»ï¼‰"""
    if not isbn_str:
        return ""
    # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«ã€æ•°å­—ä»¥å¤–ã‚’é™¤å»
    s = unicodedata.normalize("NFKC", isbn_str)
    return re.sub(r"[^0-9Xx]", "", s)

# æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹APIã§æ›¸èªŒæƒ…å ±ã‚’å–å¾—
@st.cache_resource(show_spinner=False)
def fetch_rakuten_book(isbn: str) -> dict:
    if not isbn:
        return {}
    normalized_isbn = normalize_isbn(isbn)
    if not normalized_isbn:
        return {}
    url = "https://app.rakuten.co.jp/services/api/BooksBook/Search/20170404"
    params = {
        "isbn": normalized_isbn,
        "applicationId": get_rakuten_app_id(),
        "format": "json"
    }
    try:
        res = requests.get(url, params=params)
        res.raise_for_status()
        data = res.json()
        if data.get("Items"):
            item = data["Items"][0]["Item"]
            # æ›¸å½±ã¯largeâ†’mediumâ†’smallã®é †ã§æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®
            cover_url = item.get("largeImageUrl") or item.get("mediumImageUrl") or item.get("smallImageUrl") or ""
            return {
                "title": item.get("title"),
                "author": item.get("author"),
                "publisher": item.get("publisherName"),
                "pubdate": item.get("salesDate"),
                "price": item.get("itemPrice") if item.get("itemPrice") is not None else "â€”",
                "description": item.get("itemCaption") or "â€”",
                "cover": cover_url,
                "affiliateUrl": item.get("affiliateUrl"),
                "itemUrl": item.get("itemUrl")
            }
    except Exception as e:
        print(e)
    return {}

STOPWORDS = load_stopwords()
all_adjs = sorted({adj for lst in df["adjectives"] for adj in lst})
suggestions = [w for w in all_adjs if w not in STOPWORDS]

# â”€â”€â”€ 4. ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "page" not in st.session_state:
    st.session_state.page = "home"
if "results" not in st.session_state:
    st.session_state.results = pd.DataFrame()
if "adj" not in st.session_state:
    st.session_state.adj = ""
if "detail_idx" not in st.session_state:
    st.session_state.detail_idx = None
if "raw_input" not in st.session_state:
    st.session_state.raw_input = ""
if "raw_select" not in st.session_state:
    st.session_state.raw_select = ""

# â”€â”€â”€ 5. ã‚µã‚¤ãƒ‰ãƒãƒ¼: ã‚¸ãƒ£ãƒ³ãƒ«ãƒ»ã‚¹ãƒšãƒƒã‚¯çµã‚Šè¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("çµã‚Šè¾¼ã¿")
st.sidebar.subheader("ã‚¸ãƒ£ãƒ³ãƒ«")
unique_genres = sorted({g for lst in df["genres_list"] for g in lst})
genres = st.sidebar.multiselect("ã‚¸ãƒ£ãƒ³ãƒ«", options=unique_genres, default=[])

st.sidebar.subheader("ã‚¹ãƒšãƒƒã‚¯")
spec_keys = ["erotic", "grotesque", "insane", "paranomal", "esthetic", "painful"]
spec_labels = ["ã‚¨ãƒ­", "ã‚°ãƒ­", "ç‹‚æ°—", "è¶…å¸¸", "è€½ç¾", "ç—›ã¿"]
if "spec_ranges" not in st.session_state:
    st.session_state.spec_ranges = {k: (0, 5) for k in spec_keys}
for k, label in zip(spec_keys, spec_labels):
    st.session_state.spec_ranges[k] = st.sidebar.slider(label, 0, 5, (0, 5), key=f"slider_{k}")

# ã‚¹ãƒãƒ›ã§ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æ ¼ç´ã—ã€ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã«ä½™ç™½ã‚’è¿½åŠ ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown('''
    <style>
    /* ã‚¹ãƒãƒ›ã§ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é–‰ã˜ã‚‹ */
    @media (max-width: 900px) {
        section[data-testid="stSidebar"] {
            transform: translateX(-100%);
        }
        /* ã‚µã‚¤ãƒ‰ãƒãƒ¼é–‹é–‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º */
        button[aria-label="Open sidebar"] {
            display: block;
        }
    }
    /* ã‚¹ãƒšãƒƒã‚¯ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®ä½™ç™½èª¿æ•´ */
    div[data-baseweb="slider"] {
        margin-left: 8px !important;
        margin-right: 8px !important;
    }
    </style>
''', unsafe_allow_html=True)

# â”€â”€â”€ 6. ãƒšãƒ¼ã‚¸é·ç§»ç”¨é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def to_results():
    adj = st.session_state.raw_select or st.session_state.raw_input.strip()
    st.session_state.adj = adj
    tmp = df.copy()
    # ã‚¸ãƒ£ãƒ³ãƒ«çµã‚Šè¾¼ã¿
    if genres:
        tmp = tmp[tmp["genres_list"].apply(lambda gl: any(g in gl for g in genres))]
    # ã‚¹ãƒšãƒƒã‚¯ç¯„å›²çµã‚Šè¾¼ã¿
    for k in spec_keys:
        min_v, max_v = st.session_state.spec_ranges[k]
        tmp = tmp[(tmp[k] >= min_v) & (tmp[k] <= max_v)]
    # å½¢å®¹è©çµã‚Šè¾¼ã¿
    tmp["count"] = tmp["adjectives"].apply(lambda lst: lst.count(adj))
    res = tmp[tmp["count"] > 0].sort_values("count", ascending=False)
    if not res.empty:
        res["rank"] = res["count"].rank(method="min", ascending=False).astype(int)
    st.session_state.results = res.reset_index(drop=True)
    st.session_state.page = "results"

def to_detail(idx: int):
    st.session_state.detail_idx = idx
    st.session_state.page = "detail"

def to_home():
    st.session_state.page = "home"

def to_results_page():
    st.session_state.page = "results"

# â”€â”€â”€ 7. ãƒ›ãƒ¼ãƒ ç”»é¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.page == "home":
    st.title("ğŸ“š æ„Ÿæƒ³å½¢å®¹è©ã§æ¢ã™æœ¬ã‚¢ãƒ—ãƒª")
    st.write("æ„Ÿæƒ³ã«ç™»å ´ã™ã‚‹å½¢å®¹è©ã‹ã‚‰æœ¬ã‚’æ¤œç´¢ã—ã¾ã™ã€‚")
    st.session_state.raw_input = st.text_input(
        "å½¢å®¹è©ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=st.session_state.raw_input, key="raw_input_input"
    )
    filtered = [w for w in suggestions if w.startswith(st.session_state.raw_input)] if st.session_state.raw_input else suggestions
    st.session_state.raw_select = st.selectbox(
        "å€™è£œã‹ã‚‰é¸ã¶", options=[""] + filtered, index=0, key="raw_select_box"
    )
    if st.button("ğŸ” æ¤œç´¢", on_click=to_results):
        pass

# â”€â”€â”€ 8. æ¤œç´¢çµæœç”»é¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif st.session_state.page == "results":
    if st.button("æˆ»ã‚‹", on_click=to_home):
        pass
    st.title("ğŸ” æ¤œç´¢çµæœãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    res = st.session_state.results
    if res.empty:
        st.warning("è©²å½“ã™ã‚‹æœ¬ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        for i, row in res.iterrows():
            # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãƒœã‚¿ãƒ³ã§è¡¨ç¤ºã—ã€ã‚¯ãƒªãƒƒã‚¯ã§è©³ç´°é·ç§»ï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¯ãƒªãƒƒã‚¯ã§å‹•ä½œï¼‰
            if st.button(f"{row['rank']}ä½ï¼šã€{row['title']}ã€ï¼{row['author']}ï¼ˆ{row['count']}å›ï¼‰", key=f"title_btn_{i}"):
                to_detail(i)
                st.experimental_rerun()
            # æ›¸å½±ã‚‚è¡¨ç¤º
            rakuten = fetch_rakuten_book(row.get("isbn", ""))
            if rakuten.get("cover"):
                st.image(rakuten["cover"], width=120)
            # ç´¹ä»‹æ–‡ã‚’ãƒˆã‚°ãƒ«å±•é–‹
            with st.expander("â–¼ä½œå“ç´¹ä»‹"):
                st.write(rakuten.get("description", "â€”"))

# â”€â”€â”€ 9. è©³ç´°ç”»é¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif st.session_state.page == "detail":
    # ãƒšãƒ¼ã‚¸ãƒˆãƒƒãƒ—ã«å¼·åˆ¶ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
    st.markdown('<script>window.scrollTo(0,0);</script>', unsafe_allow_html=True)
    if st.button("æˆ»ã‚‹", on_click=to_results_page):
        pass
    res = st.session_state.results
    idx = st.session_state.detail_idx
    if idx is None or idx >= len(res):
        st.error("ä¸æ­£ãªé¸æŠã§ã™ã€‚")
    else:
        book = res.loc[idx]
        st.header(f"{book['rank']}ä½ï¼šã€{book['title']}ã€ï¼{book['author']}")
        rakuten = fetch_rakuten_book(book.get("isbn", ""))
        # æ›¸å½±ã¨ãƒœã‚¿ãƒ³ã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
        col1, col2 = st.columns([1,2])
        with col1:
            cover_url = rakuten.get("cover")
            if cover_url:
                st.image(cover_url, width=100)
        with col2:
            btn1 = f'<a href="{rakuten.get("affiliateUrl") or rakuten.get("itemUrl")}" target="_blank" style="display:inline-block;padding:16px 32px;background:#FFC107;color:#222;font-weight:bold;border-radius:8px;text-decoration:none;margin-bottom:12px;">å•†å“ãƒšãƒ¼ã‚¸ã‚’é–‹ãï¼ˆæ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹ï¼‰<span style="margin-left:8px;">&#x1F517;</span></a>'
            btn2 = '<a href="https://forms.gle/Eh3fYtnzSHmN3KMSA" target="_blank" style="display:inline-block;padding:16px 32px;background:#FFC107;color:#222;font-weight:bold;border-radius:8px;text-decoration:none;">æ„Ÿæƒ³ã‚’æŠ•ç¨¿ã™ã‚‹ï¼ˆGoogleãƒ•ã‚©ãƒ¼ãƒ ï¼‰<span style="margin-left:8px;">&#x1F517;</span></a>'
            st.markdown(btn1, unsafe_allow_html=True)
            st.markdown(btn2, unsafe_allow_html=True)
        # æ›¸èªŒæƒ…å ±
        st.write(f"**å‡ºç‰ˆç¤¾**: {rakuten.get('publisher','â€”')}")
        st.write(f"**ç™ºè¡Œæ—¥**: {rakuten.get('pubdate','â€”')}")
        st.write(f"**å®šä¾¡**: {rakuten.get('price','â€”')} å††")
        st.write(f"**ç´¹ä»‹æ–‡**: {rakuten.get('description','â€”')}")

        # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        radar_vals = [book[c] for c in ["erotic","grotesque","insane","paranomal","esthetic","painful"]]
        radar_labels = ["ã‚¨ãƒ­","ã‚°ãƒ­","ç‹‚æ°—","è¶…å¸¸","è€½ç¾","ç—›ã¿"]
        fig_radar = go.Figure(
            data=[go.Scatterpolar(r=radar_vals, theta=radar_labels, fill='toself')],
            layout=go.Layout(
                title="èª­ã¿å‘³ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ",
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 5],
                        showticklabels=False,  # æ•°å­—ã‚’éè¡¨ç¤º
                        showline=False,        # è»¸ç·šã‚’éè¡¨ç¤º
                        ticks=''               # ç›®ç››ã‚Šç·šã‚‚éè¡¨ç¤º
                    )
                ),
                showlegend=False
            )
        )
        st.plotly_chart(fig_radar, use_container_width=True)
        # æ£’ã‚°ãƒ©ãƒ• TOP5
        cnt = Counter(book['adjectives'])
        for sw in STOPWORDS:
            cnt.pop(sw, None)
        top5 = cnt.most_common(5)
        if top5:
            df5 = pd.DataFrame(top5, columns=["å½¢å®¹è©","å›æ•°"])
            fig_bar = go.Figure(
                data=[go.Bar(x=df5["å½¢å®¹è©"], y=df5["å›æ•°"])],
                layout=go.Layout(
                    title="é »å‡ºå½¢å®¹è©TOP5",
                    yaxis=dict(tickmode='linear', dtick=1)
                )
            )
            st.plotly_chart(fig_bar, use_container_width=True)
        else:
            st.info("æœ‰åŠ¹ãªå½¢å®¹è©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        # Twitter APIé€£æºéƒ¨åˆ†ã¯åˆæœŸã‚¹ã‚³ãƒ¼ãƒ—å¤–ã®ãŸã‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # st.markdown("## ğŸ¦ èª­äº†ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆæœ€æ–°5ä»¶ï¼‰")
        # tweets = fetch_read_tweets(book['title'])
        # if tweets:
        #     for tw in tweets:
        #         tweet_md = (
        #             f"> {tw['text']}\n"
        #             f"â€” {tw['author_name']} (@{tw['author']}) {tw['created_at'].date()}, â¤ï¸{tw['likes']}"
        #         )
        #         st.markdown(tweet_md)
        #         st.markdown("---")
        # else:
        #     st.info("è©²å½“ã™ã‚‹èª­äº†ãƒ„ã‚¤ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        # æˆ»ã‚‹
