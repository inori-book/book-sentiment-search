import streamlit as st
import pandas as pd
import requests
from janome.tokenizer import Tokenizer
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
import re
import unicodedata
from dotenv import load_dotenv
import os
from wordcloud import WordCloud
import matplotlib.pyplot as plt

load_dotenv()

# â”€â”€â”€ 1. ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæœ€åˆã«ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="æ„Ÿæƒ³å½¢å®¹è©ã§æ¢ã™æœ¬ã‚¢ãƒ—ãƒª", layout="wide")

# â”€â”€â”€ 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & å‰å‡¦ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æŠ½å‡ºå¯¾è±¡ã®å“è©ã‚’ãƒªã‚¹ãƒˆåŒ–ï¼ˆå°†æ¥çš„ã«å¢—ã‚„ã—ã‚„ã™ã„å½¢ï¼‰
POS_TARGETS = ["å½¢å®¹è©", "å½¢å®¹å‹•è©"]

@st.cache_data
def load_abstractwords(path: str = "abstractwords.txt") -> set[str]:
    try:
        with open(path, encoding="utf-8") as f:
            words = {line.strip() for line in f if line.strip() and not line.startswith("#")}
    except FileNotFoundError:
        words = set()
    return words

ABSTRACTWORDS = load_abstractwords()

def extract_target_words(text: str) -> list[str]:
    tokens = tokenizer.tokenize(text)
    results = []
    for t in tokens:
        pos = t.part_of_speech.split(",")[0]
        if pos in POS_TARGETS:
            results.append(t.base_form)
    # æ–‡ä¸­ã«æŠ½å‡ºãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆãŒã‚ã‚Œã°å¿…ãšæŠ½å‡º
    for word in ABSTRACTWORDS:
        if word in text:
            results.append(word)
    return results

@st.cache_data
def load_data(path: str = "sample07.csv") -> pd.DataFrame:
    df = pd.read_csv(path, dtype={"ISBN": str}).fillna("")
    df.columns = [col.lower() for col in df.columns]  # åˆ—åã‚’å°æ–‡å­—ã«çµ±ä¸€
    # ã‚¸ãƒ£ãƒ³ãƒ«ã‚’ãƒªã‚¹ãƒˆåŒ–
    df["genres_list"] = df["genre"].str.split(",").apply(lambda lst: [g.strip() for g in lst if g.strip()])
    # Janome ã§å½¢å®¹è©ãƒ»å½¢å®¹å‹•è©æŠ½å‡º
    global tokenizer
    tokenizer = Tokenizer()
    df["keywords"] = df["review"].apply(extract_target_words)
    return df

df = load_data()

# â”€â”€â”€ 3. ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰å¤–éƒ¨åŒ– & å€™è£œå½¢å®¹è© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_stopwords(path: str = "stopwords.txt") -> set[str]:
    try:
        with open(path, encoding="utf-8") as f:
            words = {line.strip() for line in f if line.strip()}
    except FileNotFoundError:
        words = {"ãªã„", "ã£ã½ã„"}
    return words

def get_rakuten_app_id():
    return st.secrets.get("RAKUTEN_APP_ID") or os.getenv("RAKUTEN_APP_ID")

def normalize_isbn(isbn_str: str) -> str:
    """ISBNã‚’æ­£è¦åŒ–ã™ã‚‹ï¼ˆãƒã‚¤ãƒ•ãƒ³ã‚„ç©ºç™½ã‚’é™¤å»ï¼‰"""
    if not isbn_str:
        return ""
    # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«ã€æ•°å­—ä»¥å¤–ã‚’é™¤å»
    s = unicodedata.normalize("NFKC", isbn_str)
    return re.sub(r"[^0-9Xx]", "", s)

# æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹APIã§æ›¸èªŒæƒ…å ±ã‚’å–å¾—
@st.cache_resource(show_spinner=False)
def fetch_rakuten_book(isbn: str) -> dict:
    if not isbn:
        return {}
    normalized_isbn = normalize_isbn(isbn)
    if not normalized_isbn:
        return {}
    url = "https://app.rakuten.co.jp/services/api/BooksBook/Search/20170404"
    params = {
        "isbn": normalized_isbn,
        "applicationId": get_rakuten_app_id(),
        "format": "json"
    }
    try:
        res = requests.get(url, params=params)
        res.raise_for_status()
        data = res.json()
        if data.get("Items"):
            item = data["Items"][0]["Item"]
            # æ›¸å½±ã¯largeâ†’mediumâ†’smallã®é †ã§æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®
            cover_url = item.get("largeImageUrl") or item.get("mediumImageUrl") or item.get("smallImageUrl") or ""
            return {
                "title": item.get("title"),
                "author": item.get("author"),
                "publisher": item.get("publisherName"),
                "pubdate": item.get("salesDate"),
                "price": item.get("itemPrice") if item.get("itemPrice") is not None else "â€”",
                "description": item.get("itemCaption") or "â€”",
                "cover": cover_url,
                "affiliateUrl": item.get("affiliateUrl"),
                "itemUrl": item.get("itemUrl")
            }
    except Exception as e:
        print(e)
    return {}

STOPWORDS = load_stopwords()
all_keywords = sorted({kw for lst in df["keywords"] for kw in lst})
suggestions = [w for w in all_keywords if w not in STOPWORDS]

# â”€â”€â”€ 4. ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "page" not in st.session_state:
    st.session_state.page = "home"
if "results" not in st.session_state:
    st.session_state.results = pd.DataFrame()
if "adj" not in st.session_state:
    st.session_state.adj = ""
if "detail_idx" not in st.session_state:
    st.session_state.detail_idx = None
if "raw_input" not in st.session_state:
    st.session_state.raw_input = ""
if "raw_select" not in st.session_state:
    st.session_state.raw_select = ""

# â”€â”€â”€ 5. ã‚µã‚¤ãƒ‰ãƒãƒ¼: ã‚¸ãƒ£ãƒ³ãƒ«ãƒ»ã‚¹ãƒšãƒƒã‚¯çµã‚Šè¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# st.sidebar.header("çµã‚Šè¾¼ã¿")
# st.sidebar.subheader("ã‚¸ãƒ£ãƒ³ãƒ«")
# unique_genres = sorted({g for lst in df["genres_list"] for g in lst})
# genres = st.sidebar.multiselect("ã‚¸ãƒ£ãƒ³ãƒ«", options=unique_genres, default=[])
#
# st.sidebar.subheader("ã‚¹ãƒšãƒƒã‚¯")
# spec_keys = ["erotic", "grotesque", "insane", "paranomal", "esthetic", "painful"]
# spec_labels = ["ã‚¨ãƒ­", "ã‚°ãƒ­", "ç‹‚æ°—", "è¶…å¸¸", "è€½ç¾", "ç—›ã¿"]
# if "spec_ranges" not in st.session_state:
#     st.session_state.spec_ranges = {k: (0, 5) for k in spec_keys}
# for k, label in zip(spec_keys, spec_labels):
#     st.session_state.spec_ranges[k] = st.sidebar.slider(label, 0, 5, (0, 5), key=f"slider_{k}")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼é–‹é–‰ãƒœã‚¿ãƒ³ã‚’å¸¸æ™‚è¡¨ç¤ºã™ã‚‹CSSã®ã¿é©ç”¨
st.markdown('''
    <style>
    button[aria-label="Open sidebar"] {
        display: block !important;
        opacity: 1 !important;
        z-index: 1001 !important;
    }
    /* ã‚¹ãƒšãƒƒã‚¯ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®ä½™ç™½èª¿æ•´ */
    div[data-baseweb="slider"] {
        margin-left: 8px !important;
        margin-right: 8px !important;
    }
    </style>
''', unsafe_allow_html=True)

# â”€â”€â”€ 6. ãƒšãƒ¼ã‚¸é·ç§»ç”¨é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def to_results():
    adj = st.session_state.raw_select or st.session_state.raw_input.strip()
    st.session_state.adj = adj
    tmp = df.copy()
    # ã‚¸ãƒ£ãƒ³ãƒ«çµã‚Šè¾¼ã¿
    if genres:
        tmp = tmp[tmp["genres_list"].apply(lambda gl: any(g in gl for g in genres))]
    # ã‚¹ãƒšãƒƒã‚¯ç¯„å›²çµã‚Šè¾¼ã¿
    for k in spec_keys:
        min_v, max_v = st.session_state.spec_ranges[k]
        tmp = tmp[(tmp[k] >= min_v) & (tmp[k] <= max_v)]
    # å½¢å®¹è©çµã‚Šè¾¼ã¿
    tmp["count"] = tmp["keywords"].apply(lambda lst: lst.count(adj))
    res = tmp[tmp["count"] > 0].sort_values("count", ascending=False)
    if not res.empty:
        res["rank"] = res["count"].rank(method="min", ascending=False).astype(int)
    st.session_state.results = res.reset_index(drop=True)
    st.session_state.page = "results"

def to_detail(idx: int):
    st.session_state.detail_idx = idx
    st.session_state.page = "detail"

def to_home():
    st.session_state.page = "home"

def to_results_page():
    st.session_state.page = "results"

# â”€â”€â”€ 7. ãƒ›ãƒ¼ãƒ ç”»é¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.page == "home":
    # ã‚«ã‚¹ã‚¿ãƒ CSSã§èƒŒæ™¯ãƒ»ãƒ•ã‚©ãƒ³ãƒˆãƒ»è‰²ãƒ»ä½™ç™½ãªã©ã‚’èª¿æ•´
    st.markdown(f'''
        <style>
        /* èƒŒæ™¯ç”»åƒï¼‹é»’ãƒ¬ã‚¤ãƒ¤ãƒ¼ */
        body {{
            position: relative;
            min-height: 100vh;
            background: url('background.png') no-repeat center center fixed;
            background-size: cover;
        }}
        body::before {{
            content: "";
            position: fixed;
            top: 0; left: 0; right: 0; bottom: 0;
            width: 100vw; height: 100vh;
            background: rgba(0,0,0,0.2);
            z-index: 0;
            pointer-events: none;
        }}
        /* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å‰é¢ã« */
        .main, .block-container, .css-18e3th9, .css-1d391kg {{
            position: relative;
            z-index: 1;
        }}
        /* å…¨ä½“å¹…375pxä¸­å¤®å¯„ã› */
        div[data-testid="stVerticalBlock"] > div:first-child {{
            max-width: 375px;
            margin: 0 auto;
            background: transparent;
        }}
        /* ã‚¿ã‚¤ãƒˆãƒ« */
        .custom-title {{
            font-size: 30px !important;
            font-weight: bold !important;
            color: #FFFFFF !important;
            padding: 84px 10px 10px 10px !important;
            letter-spacing: 0.02em;
        }}
        .custom-title span.colon {{
            color: #FF9500 !important;
        }}
        /* ãƒªãƒ¼ãƒ‰æ–‡ãƒ»ä¸‹éƒ¨ãƒ†ã‚­ã‚¹ãƒˆ */
        .custom-lead, .custom-bottom1, .custom-bottom2 {{
            font-size: 16px !important;
            color: #FFFFFF !important;
            padding: 10px !important;
        }}
        .custom-bottom1 {{
            padding-top: 0 !important;
        }}
        .custom-bottom2 {{
            padding-top: 0 !important;
        }}
        /* æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ ãƒ©ãƒ™ãƒ« */
        .custom-label {{
            font-size: 14px !important;
            color: #FFFFFF !important;
            padding: 10px 10px 0 10px !important;
        }}
        /* ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ãƒ»ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ */
        .custom-input, .custom-select {{
            width: 167px !important;
            height: 88px !important;
            padding: 10px !important;
            font-size: 14px !important;
            color: #FFFFFF !important;
            background: rgba(0,0,0,0.4) !important;
            border-radius: 8px !important;
            border: 1px solid #94A3B8 !important;
            margin: 0 5px 0 0 !important;
        }}
        /* ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼è‰² */
        input::placeholder, textarea::placeholder, .custom-select option:disabled {{
            color: #94A3B8 !important;
            opacity: 1 !important;
        }}
        /* æ¤œç´¢ãƒœã‚¿ãƒ³ */
        .custom-search-btn button {{
            width: 100%;
            font-size: 16px !important;
            font-weight: bold !important;
            color: #000000 !important;
            background: #FF9500 !important;
            border-radius: 8px !important;
            border: none !important;
            padding: 16px 0 !important;
            margin: 20px 10px 20px 10px !important;
        }}
        /* åŒºåˆ‡ã‚Šç·š */
        .custom-divider {{
            width: 355px;
            height: 1px;
            background: #FFFFFF;
            opacity: 0.3;
            margin: 116px 10px 10px 10px !important;
        }}
        /* Googleãƒ•ã‚©ãƒ¼ãƒ ãƒœã‚¿ãƒ³ */
        .custom-gform-btn a {{
            display: block;
            width: 100%;
            text-align: center;
            font-size: 16px !important;
            font-weight: bold !important;
            color: #000000 !important;
            background: #FF9500 !important;
            border-radius: 8px !important;
            text-decoration: none !important;
            padding: 16px 0 !important;
            margin: 20px 10px 10px 10px !important;
        }}
        </style>
    ''', unsafe_allow_html=True)

    # ã‚¿ã‚¤ãƒˆãƒ«
    st.markdown('<div class="custom-title">YOMIAJI <span class="colon">:</span> Horror</div>', unsafe_allow_html=True)
    # ãƒªãƒ¼ãƒ‰æ–‡
    st.markdown('<div class="custom-lead">èª­ã¿å‘³ã‹ã‚‰æœ¬ãŒæ¤œç´¢ã§ãã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚<br>æ€–ãã¦è€½ç¾ã§ã‚¤ãƒ³ãƒ¢ãƒ©ãƒ«ãªæœ¬ãŒæ¢ã›ã¾ã™ã€‚</div>', unsafe_allow_html=True)

    # æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆæ¨ªä¸¦ã³ï¼‰
    col1, col2 = st.columns(2, gap="small")
    with col1:
        st.markdown('<div class="custom-label">ãƒ•ãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã§æ¤œç´¢</div>', unsafe_allow_html=True)
        st.session_state.raw_input = st.text_area(
            "å½¢å®¹è©ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=st.session_state.raw_input, key="raw_input_input",
            placeholder="ä¾‹ï¼šç¾ã—ã„ã€åˆ‡ãªã„â€¦",
            height=70,
            label_visibility="collapsed"
        )
    with col2:
        st.markdown('<div class="custom-label">å€™è£œã‹ã‚‰æ¤œç´¢</div>', unsafe_allow_html=True)
        filtered = [w for w in suggestions if w.startswith(st.session_state.raw_input)] if st.session_state.raw_input else suggestions
        st.session_state.raw_select = st.selectbox(
            "å€™è£œã‹ã‚‰é¸ã¶", options=[""] + filtered, index=0, key="raw_select_box",
            placeholder="å½¢å®¹è©ã‚’é¸æŠ",
            label_visibility="collapsed"
        )
    # æ¤œç´¢ãƒœã‚¿ãƒ³
    with st.container():
        st.markdown('<div class="custom-search-btn">', unsafe_allow_html=True)
        if st.button("æ¤œç´¢", on_click=to_results, key="search_btn_home"):
            pass
        st.markdown('</div>', unsafe_allow_html=True)
    # åŒºåˆ‡ã‚Šç·š
    st.markdown('<div class="custom-divider"></div>', unsafe_allow_html=True)
    # ä¸‹éƒ¨ãƒ†ã‚­ã‚¹ãƒˆ
    st.markdown('<div class="custom-bottom1">ã‚ãªãŸãŒèª­ã‚“ã æœ¬ã®æ„Ÿæƒ³ã‚’æŠ•ç¨¿ã—ã¦ãã ã•ã„</div>', unsafe_allow_html=True)
    st.markdown('<div class="custom-bottom2">ã‚ãªãŸã®æ„Ÿæƒ³ãŒã‚µãƒ¼ãƒ“ã‚¹ã‚’è‚²ã¦ã¾ã™ã€‚</div>', unsafe_allow_html=True)
    # Googleãƒ•ã‚©ãƒ¼ãƒ ãƒœã‚¿ãƒ³
    st.markdown('<div class="custom-gform-btn"><a href="https://forms.gle/Eh3fYtnzSHmN3KMSA" target="_blank">Googleãƒ•ã‚©ãƒ¼ãƒ </a></div>', unsafe_allow_html=True)

# â”€â”€â”€ 8. æ¤œç´¢çµæœç”»é¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif st.session_state.page == "results":
    if st.button("æˆ»ã‚‹", on_click=to_home):
        pass
    # æ¤œç´¢çª“ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”»é¢ä¸Šéƒ¨ã«å¸¸æ™‚è¡¨ç¤º
    st.markdown("## ğŸ” å†æ¤œç´¢")
    st.session_state.raw_input = st.text_input(
        "å½¢å®¹è©ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=st.session_state.raw_input, key="raw_input_results"
    )
    filtered = [w for w in suggestions if w.startswith(st.session_state.raw_input)] if st.session_state.raw_input else suggestions
    st.session_state.raw_select = st.selectbox(
        "å€™è£œã‹ã‚‰é¸ã¶", options=[""] + filtered, index=0, key="raw_select_results"
    )
    if st.button("ğŸ” æ¤œç´¢", on_click=to_results, key="search_btn_results"):
        pass
    st.title("ï¿½ï¿½ æ¤œç´¢çµæœãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    # ãƒ‘ãƒ³ããšãƒªã‚¹ãƒˆã‚’ã‚¿ã‚¤ãƒˆãƒ«ç›´ä¸‹ã«è¡¨ç¤ºï¼ˆãƒ›ãƒ¼ãƒ ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒªãƒ³ã‚¯é¢¨ãƒœã‚¿ãƒ³ï¼‰
    col1, col2 = st.columns([1, 10])
    with col1:
        btn = st.button("ãƒ›ãƒ¼ãƒ ", key="breadcrumb_home")
        st.markdown(
            """
            <style>
            div[data-testid="stButton"] button {
                background: none !important;
                color: #1a73e8 !important;
                text-decoration: underline !important;
                border: none !important;
                padding: 0 !important;
                font-size: 1em !important;
                font-weight: normal !important;
            }
            </style>
            """,
            unsafe_allow_html=True
        )
        if btn:
            to_home()
    with col2:
        st.markdown(f"> ã€Œ{st.session_state.adj}ã€ã®æ¤œç´¢çµæœ")
    res = st.session_state.results
    if res.empty:
        st.warning("è©²å½“ã™ã‚‹æœ¬ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        for i, row in res.iterrows():
            if st.button(f"{row['rank']}ä½ï¼šã€{row['title']}ã€ï¼{row['author']}ï¼ˆ{row['count']}å›ï¼‰", key=f"title_btn_{i}"):
                to_detail(i)
                st.rerun()
            rakuten = fetch_rakuten_book(row.get("isbn", ""))
            if rakuten.get("cover"):
                st.image(rakuten["cover"], width=120)
            with st.expander("â–¼ä½œå“ç´¹ä»‹"):
                st.write(rakuten.get("description", "â€”"))

# â”€â”€â”€ 9. è©³ç´°ç”»é¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif st.session_state.page == "detail":
    # ãƒšãƒ¼ã‚¸ãƒˆãƒƒãƒ—ã«å¼·åˆ¶ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
    st.markdown('<script>window.scrollTo(0,0);</script>', unsafe_allow_html=True)
    if st.button("æˆ»ã‚‹", on_click=to_results_page):
        pass
    res = st.session_state.results
    idx = st.session_state.detail_idx
    if idx is None or idx >= len(res):
        st.error("ä¸æ­£ãªé¸æŠã§ã™ã€‚")
    else:
        book = res.loc[idx]
        st.header(f"{book['rank']}ä½ï¼šã€{book['title']}ã€ï¼{book['author']}")
        rakuten = fetch_rakuten_book(book.get("isbn", ""))
        # æ›¸å½±ã¨ãƒœã‚¿ãƒ³ã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
        col1, col2 = st.columns([1,2])
        with col1:
            cover_url = rakuten.get("cover")
            if cover_url:
                st.image(cover_url, width=100)
        with col2:
            btn1 = f'<a href="{rakuten.get("affiliateUrl") or rakuten.get("itemUrl")}" target="_blank" style="display:inline-block;padding:16px 32px;background:#FFC107;color:#222;font-weight:bold;border-radius:8px;text-decoration:none;margin-bottom:12px;">å•†å“ãƒšãƒ¼ã‚¸ã‚’é–‹ãï¼ˆæ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹ï¼‰<span style="margin-left:8px;">&#x1F517;</span></a>'
            btn2 = '<a href="https://forms.gle/Eh3fYtnzSHmN3KMSA" target="_blank" style="display:inline-block;padding:16px 32px;background:#FFC107;color:#222;font-weight:bold;border-radius:8px;text-decoration:none;">æ„Ÿæƒ³ã‚’æŠ•ç¨¿ã™ã‚‹ï¼ˆGoogleãƒ•ã‚©ãƒ¼ãƒ ï¼‰<span style="margin-left:8px;">&#x1F517;</span></a>'
            st.markdown(btn1, unsafe_allow_html=True)
            st.markdown(btn2, unsafe_allow_html=True)
        # æ›¸èªŒæƒ…å ±
        st.write(f"**å‡ºç‰ˆç¤¾**: {rakuten.get('publisher','â€”')}")
        st.write(f"**ç™ºè¡Œæ—¥**: {rakuten.get('pubdate','â€”')}")
        st.write(f"**å®šä¾¡**: {rakuten.get('price','â€”')} å††")
        st.write(f"**ç´¹ä»‹æ–‡**: {rakuten.get('description','â€”')}")

        # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        radar_vals = [book[c] for c in ["erotic","grotesque","insane","paranomal","esthetic","painful"]]
        radar_labels = ["ã‚¨ãƒ­","ã‚°ãƒ­","ç‹‚æ°—","è¶…å¸¸","è€½ç¾","ç—›ã¿"]
        fig_radar = go.Figure(
            data=[go.Scatterpolar(r=radar_vals, theta=radar_labels, fill='toself')],
            layout=go.Layout(
                title="èª­ã¿å‘³ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ",
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 5],
                        showticklabels=False,  # æ•°å­—ã‚’éè¡¨ç¤º
                        showline=False,        # è»¸ç·šã‚’éè¡¨ç¤º
                        ticks=''               # ç›®ç››ã‚Šç·šã‚‚éè¡¨ç¤º
                    )
                ),
                showlegend=False
            )
        )
        st.plotly_chart(fig_radar, use_container_width=True, config={"staticPlot": True})
        # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰è¡¨ç¤º
        cnt = Counter(book['keywords'])
        for sw in STOPWORDS:
            cnt.pop(sw, None)
        if cnt:
            # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ
            st.markdown("### æ„Ÿæƒ³ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰")
            wc = WordCloud(font_path='ipag.ttf', width=600, height=400, background_color='white', colormap='tab20').generate_from_frequencies(dict(cnt))
            fig, ax = plt.subplots(figsize=(6, 4))
            ax.imshow(wc, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)
        else:
            st.info("æœ‰åŠ¹ãªãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        # Twitter APIé€£æºéƒ¨åˆ†ã¯åˆæœŸã‚¹ã‚³ãƒ¼ãƒ—å¤–ã®ãŸã‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # st.markdown("## ğŸ¦ èª­äº†ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆæœ€æ–°5ä»¶ï¼‰")
        # tweets = fetch_read_tweets(book['title'])
        # if tweets:
        #     for tw in tweets:
        #         tweet_md = (
        #             f"> {tw['text']}\n"
        #             f"â€” {tw['author_name']} (@{tw['author']}) {tw['created_at'].date()}, â¤ï¸{tw['likes']}"
        #         )
        #         st.markdown(tweet_md)
        #         st.markdown("---")
        # else:
        #     st.info("è©²å½“ã™ã‚‹èª­äº†ãƒ„ã‚¤ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        # æˆ»ã‚‹
